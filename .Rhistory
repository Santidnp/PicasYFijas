#creo entrenamiento y validaci?n
celular.train<-rbind(mayorcero.train,menoruno.train)
celular.valid<-rbind(mayorcero.valid,menoruno.valid)
#chequeo que todo va bien
table(celular.train$resultado)
table(celular.valid$resultado)
table(celular.test$resultado)
prop.table(table(celular.train$resultado))
prop.table(table(celular.valid$resultado))
prop.table(table(celular.test$resultado))
prop.table(table(trainfin$resultado))
#_____________________________________________________________________________________________________________________
#Modelo de regresion
modelo.balance<-glm(resultado~.,family=binomial,celular.train)
#_____________________________________________________________________________________________________________________
#Modelo de regresion
modelo.balance<-glm(resultado~.,family=binomial,celular.train)
#trace=0 impide ver todos los detalles de la optimizaci?n stepwise
stepbalance<-step(modelo.balance, direction="both", trace=0)
summary(stepbalance)
coeficientes2<-stepbalance$coefficients
odd_changeb<-exp(coeficientes2)
odd_changeb
##Train Probar
resultado.train <- predict(stepbalance,newdata = celular.train,type='response')
resultado.train <- ifelse(resultado.train > 0.5,1,0)
pr.train <- prediction(resultado.train,celular.train$resultado)
conf.train <- confusionMatrix(as.factor(resultado.train),as.factor(celular.train$resultado), positive = "1")
conf.train$table
conf.train$byClass
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
resultado.test <- predict(stepbalance,newdata = celular.test,type='response')
resultado.test <- ifelse(resultado.test > 0.5,1,0)
pr.test <- prediction(resultado.test,celular.test$resultado)
conf.test <- confusionMatrix(as.factor(resultado.test),as.factor(celular.test$resultado), positive = "1")
conf.test$table
conf.test$byClass
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
#crea el pron?stico en validaci?n
resultado<-predict(stepbalance,newdata = testfin,type='response')
resultado<-ifelse(resultado > 0.5,1,0)
conftest2<-confusionMatrix(as.factor(resultado),as.factor(celular.test$resultado), positive = "1")
conftest2$table
conftest2$byClass
conf.test <- confusionMatrix(as.factor(resultado.test),as.factor(celular.test$resultado), positive = "1")
conf.test$table
conf.test$byClass
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
#crea el pron?stico en validaci?n
resultado<-predict(stepbalance,newdata = testfin,type='response')
resultado<-ifelse(resultado > 0.5,1,0)
conftest2<-confusionMatrix(as.factor(resultado),as.factor(celular.test$resultado), positive = "1")
X_train <- celular.train %>% select(-c(resultado)) %>% as.matrix()
y_train <- celular.train %>% select(resultado) %>% as.matrix()
modlasso <- glmnet(X_train, y_train, family = "binomial", alpha = 1, lambda = NULL)
summary(modlasso)
modelasso2 <- glmnet(X_train, y_train, family = "binomial", alpha = 1,type.measure='auc',lambda = 0.01)
plot(modelasso2)
summary(modlasso2)
summary(modelasso2)
##Train Probar
resultado.train <- predict(modelasso2, s=modlasso$lambda.min, newx=X_train, type="class")
resultado.train <- as.numeric(resultado.train)
pr.train <- prediction(resultado.train,celular.train$resultado)
conf.train <- confusionMatrix(as.factor(resultado.train),as.factor(celular.train$resultado), positive = "0")
conf.train$table
conf.train$byClass
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
curvaROC.train
auc <- performance(pr.train,measure = "auc")
aucf <- auc@y.values[[1]]
aucf
X_test <- testfin %>% as.matrix()
resultado.Final <- predict(modelasso2, s=modlasso$lambda.min, newx= X_test, type="class")
resultado.Final <- as.numeric(resultado.Final)
df_final <- cbind(testfin$id,resultado.Final) %>% as.data.frame()
colnames(df_final) <- c("id", "resultado")
df_final$resultado<-as.factor(df_final$resultado)
#Modelo Random Forest con muestra balanceada
colnames(celular.train) <- unlist(lapply(colnames(celular.train),make.names)) #Random forest solo acpeta variables con nombres sintacticamente correctos
colnames(celular.test) <- unlist(lapply(colnames(celular.test),make.names))
colnames(testfin) <- unlist(lapply(colnames(testfin),make.names))
rf <- randomForest(formula = resultado ~ ., data = celular.train)
##Rendimiento en train
predrf <- predict(rf,celular.train)
predrf <- ifelse(predrf > 0.5,1,0) %>% as.numeric()
pr.train <- prediction(predrf,celular.train$resultado)
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
curvaROC.train
auc <- performance(pr.train,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
predrf.test <- predict(rf,celular.test)
predrf.test <- ifelse(predrf.test > 0.5,1,0) %>% as.numeric()
pr.test <- prediction(predrf.test,celular.test$resultado)
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
curvaROC.test
auc <- performance(pr.test,measure = "auc")
aucf
auc <- performance(pr.test,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
resultado.Final <- predict(rf,testfin)
resultado.Final <- ifelse(resultado.Final >0.5,1,0) %>% as.numeric()
df_finalrf <- cbind(testfin$id,resultado.Final) %>% as.data.frame()
colnames(df_finalrf) <- c("id", "resultado")
df_finalrf$resultado<-as.factor(df_finalrf$resultado)
df_finalrf
write.csv(df_finalrf, file="Resultadosrf1.csv",row.names = F)
if (!require('readxl')) install.packages('readxl')
if (!require('caret')) install.packages('caret')
if (!require('ROCR')) install.packages('ROCR')
if (!require('lift')) install.packages('lift')
if (!require('ggplot2')) install.packages('ggplot2')
library(tidyverse)
library(glmnet)
library(randomForest)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
test<-read_excel("testelco.xlsx")
train<-read_excel("traintelco.xlsx")
Factores <- c('tipo cliente','Factura online','Plan de datos')
train[,Factores] <- apply(train[,Factores],2,as.factor)
test[,Factores] <- apply(test[,Factores],2,as.factor)
# library(caret)
trainwin<-dummyVars("~.",data=train)
trainfin<-as.data.frame(predict(trainwin,newdata=train))
testwin<-dummyVars("~.",data=test)
testfin<-as.data.frame(predict(testwin,newdata=test))
#Comprobar si la base de datos esta balanceada
balance<-table(train$resultado)
prop.table(balance)
___________________________________________________________________________________________________________________
#Balanceo
##separamos ceros y unos
mayorcero<-subset(trainfin,trainfin$resultado==0)
menoruno<-subset(trainfin,trainfin$resultado==1)
#en ambas bases el 20% es prueba
set.seed(1234)
#20% de ceros
sample <- sample.int(nrow(mayorcero), round(.2*nrow(mayorcero)))
mayorcero.test <- mayorcero[sample, ]
mayorcero.rest <- mayorcero[-sample, ]
#20% de unos
sample <- sample.int(nrow(menoruno), round(.2*nrow(menoruno)))
menoruno.test <- menoruno[sample, ]
menoruno.rest <- menoruno[-sample, ]
#fundo las dos
celular.test<-rbind(mayorcero.test,menoruno.test)
nrow(celular.test)
sample <- sample.int(nrow(menoruno.rest), round(.5*nrow(menoruno.rest)))
menoruno.train <- menoruno.rest[sample, ]
menoruno.valid <- menoruno.rest[-sample, ]
#pongo la misma cantidad de ceros y unos en entrenamiento:
sample <- sample.int(nrow(mayorcero.rest), nrow(menoruno.train))
mayorcero.train <- mayorcero.rest[sample, ]
mayorcero.valid <- mayorcero.rest[-sample, ]
#creo entrenamiento y validaci?n
celular.train<-rbind(mayorcero.train,menoruno.train)
celular.valid<-rbind(mayorcero.valid,menoruno.valid)
#chequeo que todo va bien
table(celular.train$resultado)
table(celular.valid$resultado)
table(celular.test$resultado)
prop.table(table(celular.train$resultado))
prop.table(table(celular.valid$resultado))
prop.table(table(celular.test$resultado))
prop.table(table(trainfin$resultado))
#_____________________________________________________________________________________________________________________
#Modelo de regresion
modelo.balance<-glm(resultado~.,family=binomial,celular.train)
#trace=0 impide ver todos los detalles de la optimizaci?n stepwise
stepbalance<-step(modelo.balance, direction="both", trace=0)
summary(stepbalance)
coeficientes2<-stepbalance$coefficients
odd_changeb<-exp(coeficientes2)
odd_changeb
##Train Probar
resultado.train <- predict(stepbalance,newdata = celular.train,type='response')
resultado.train <- ifelse(resultado.train > 0.5,1,0)
pr.train <- prediction(resultado.train,celular.train$resultado)
conf.train <- confusionMatrix(as.factor(resultado.train),as.factor(celular.train$resultado), positive = "1")
conf.train$table
conf.train$byClass
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
##Test Probar
resultado.test <- predict(stepbalance,newdata = celular.test,type='response')
resultado.test <- ifelse(resultado.test > 0.5,1,0)
pr.test <- prediction(resultado.test,celular.test$resultado)
conf.test <- confusionMatrix(as.factor(resultado.test),as.factor(celular.test$resultado), positive = "1")
conf.test$table
conf.test$byClass
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
X_train <- celular.train %>% select(-c(resultado)) %>% as.matrix()
y_train <- celular.train %>% select(resultado) %>% as.matrix()
modlasso <- glmnet(X_train, y_train, family = "binomial", alpha = 1, lambda = NULL)
summary(modlasso)
modelasso2 <- glmnet(X_train, y_train, family = "binomial", alpha = 1,type.measure='auc',lambda = 0.01)
plot(modelasso2)
summary(modelasso2)
##Train Probar
resultado.train <- predict(modelasso2, s=modlasso$lambda.min, newx=X_train, type="class")
resultado.train <- as.numeric(resultado.train)
pr.train <- prediction(resultado.train,celular.train$resultado)
conf.train <- confusionMatrix(as.factor(resultado.train),as.factor(celular.train$resultado), positive = "0")
conf.train$table
conf.train$byClass
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
curvaROC.train
auc <- performance(pr.train,measure = "auc")
aucf <- auc@y.values[[1]]
X_test <- testfin %>% as.matrix()
resultado.Final <- predict(modelasso2, s=modlasso$lambda.min, newx= X_test, type="class")
resultado.Final <- as.numeric(resultado.Final)
df_final <- cbind(testfin$id,resultado.Final) %>% as.data.frame()
colnames(df_final) <- c("id", "resultado")
df_final$resultado<-as.factor(df_final$resultado)
#Modelo Random Forest con muestra balanceada
colnames(celular.train) <- unlist(lapply(colnames(celular.train),make.names)) #Random forest solo acpeta variables con nombres sintacticamente correctos
colnames(celular.test) <- unlist(lapply(colnames(celular.test),make.names))
colnames(testfin) <- unlist(lapply(colnames(testfin),make.names))
rf <- randomForest(formula = resultado ~ ., data = celular.train)
##Rendimiento en train
predrf <- predict(rf,celular.train)
predrf <- ifelse(predrf > 0.5,1,0) %>% as.numeric()
pr.train <- prediction(predrf,celular.train$resultado)
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
curvaROC.train
auc <- performance(pr.train,measure = "auc")
aucf
auc
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
predrf.test <- predict(rf,celular.test)
predrf.test <- ifelse(predrf.test > 0.5,1,0) %>% as.numeric()
pr.test <- prediction(predrf.test,celular.test$resultado)
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
curvaROC.test
auc <- performance(pr.test,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
plot(rf)
rf <- randomForest(formula = resultado ~ ., data = celular.train,ntree = 1000)
##Rendimiento en train
predrf <- predict(rf,celular.train)
predrf <- ifelse(predrf > 0.5,1,0) %>% as.numeric()
pr.train <- prediction(predrf,celular.train$resultado)
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
auc <- performance(pr.train,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
predrf.test <- predict(rf,celular.test)
predrf.test <- ifelse(predrf.test > 0.5,1,0) %>% as.numeric()
pr.test <- prediction(predrf.test,celular.test$resultado)
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
curvaROC.test
auc <- performance(pr.test,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
plot(rf)
detectCores()
library(doParallel)
detectCores()
library(doParallel)
cores <- detectCores()
registerDoParallel(cores)
ntrees <- 500
rfParallel <- function(x){
foreach(ntree.iter = rep(ceiling(ntrees / cores), cores),
.combine = combine, .packages = "randomForest") %dopar% {
randomForest(formula.rf, data = x, ntree = ntree.iter,
do.trace = FALSE, subset = (if.test == 0),
keep.forest = TRUE, importance = TRUE)
}
}
rf.parallel <- rfParallel(celular.train)
rfParallel <- function(x){
foreach(ntree.iter = rep(ceiling(ntrees / cores), cores),
.combine = combine, .packages = "randomForest") %dopar% {
randomForest(resultado ~ ., data = x, ntree = ntree.iter,
do.trace = FALSE, subset = (if.test == 0),
keep.forest = TRUE, importance = TRUE)
}
}
rf.parallel <- rfParallel(celular.train)
rfParallel <- function(x){
foreach(ntree.iter = rep(ceiling(ntrees / cores), cores),
.combine = combine, .packages = "randomForest") %dopar% {
randomForest(resultado ~ ., data = x, ntree = ntree.iter,
do.trace = FALSE, subset = (celular.train == 0),
keep.forest = TRUE, importance = TRUE)
}
}
rf.parallel <- rfParallel(celular.train)
rfParallel <- function(x){
foreach(ntree.iter = rep(ceiling(ntrees / cores), cores),
.combine = combine, .packages = "randomForest") %dopar% {
randomForest(resultado ~ ., data = x, ntree = ntree.iter,
do.trace = FALSE, subset = (celular.train$resultado == 0),
keep.forest = TRUE, importance = TRUE)
}
}
rf.parallel <- rfParallel(celular.train)
rfParallel <- function(x){
foreach(ntree.iter = rep(ceiling(ntrees / cores), cores),
.combine = combine, .packages = "randomForest") %dopar% {
randomForest(resultado ~ ., data = x, ntree = ntree.iter,
do.trace = FALSE, subset = (celular.train$resultado == 0),
keep.forest = TRUE, importance = TRUE)
}
}
rf.parallel <- rfParallel(celular.train)
rfParallel <- function(x){
foreach(ntree.iter = rep(ceiling(ntrees / cores), cores),
.combine = combine, .packages = "randomForest") %dopar% {
randomForest(resultado ~ ., data = x, ntree = ntree.iter,
do.trace = FALSE,
keep.forest = TRUE, importance = TRUE)
}
}
rf.parallel <- rfParallel(celular.train)
plot( rf.parallel)
predrf <- predict(rf.parallel,celular.train)
predrf
predrf <- ifelse(predrf > 0.5,1,0) %>% as.numeric()
predrf
predrf.test <- predict(rf.parallel,celular.test)
predrf.test <- ifelse(predrf.test > 0.5,1,0) %>% as.numeric()
pr.test <- prediction(predrf.test,celular.test$resultado)
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
curvaROC.test
auc <- performance(pr.test,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
predrf.valid <- predict(rf.parallel,celular.valid)
colnames(celular.valid) <- unlist(lapply(colnames(celular.valid),make.names))
predrf.valid <- predict(rf.parallel,celular.valid)
predrf.valid <- ifelse(predrf.valid > 0.5,1,0) %>% as.numeric()
pr.valid <- prediction(predrf.valid,celular.test$resultado)
predrf.valid
pr.valid <- prediction(predrf.valid,celular.valid$resultado)
curvaROC.test <- performance(pr.valid,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
curvaROC.test
auc <- performance(pr.test,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
curvaROC.valid <- performance(pr.valid,measure="tpr",x.measure="fpr")
curvaROC.valid <- performance(pr.valid,measure="tpr",x.measure="fpr")
plot(curvaROC.valid)
auc <- performance(pr.valid,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
resultado.Final <- predict(rf.parallel,testfin)
resultado.Final <- ifelse(resultado.Final >0.5,1,0) %>% as.numeric()
df_finalrf <- cbind(testfin$id,resultado.Final) %>% as.data.frame()
colnames(df_finalrf) <- c("id", "resultado")
df_finalrf$resultado<-as.factor(df_finalrf$resultado)
write.csv(df_finalrf, file="Resultadosrfparallel.csv",row.names = F)
if (!require('readxl')) install.packages('readxl')
if (!require('caret')) install.packages('caret')
if (!require('ROCR')) install.packages('ROCR')
if (!require('lift')) install.packages('lift')
if (!require('ggplot2')) install.packages('ggplot2')
library(tidyverse)
library(glmnet)
library(randomForest)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
cores <- detectCores()
getwd()
test<-read_excel("testelco.xlsx")
train<-read_excel("traintelco.xlsx")
Factores <- c('tipo cliente','Factura online','Plan de datos')
train[,Factores] <- apply(train[,Factores],2,as.factor)
test[,Factores] <- apply(test[,Factores],2,as.factor)
View(train)
Factores <- c('tipo cliente','Factura online','Plan de datos')
escalar <- c('Antigüedad Equipo','facturación','mora','minutos')
train[,escalar]
test[,escalar]
scale(test[,escalar])
train[,Factores] <- apply(train[,Factores],2,as.factor)
test[,Factores] <- apply(test[,Factores],2,as.factor)
train[,escalar] <- apply(train[,escalar],2,scale)
#_________________________________________________________________________________________________________________________
#Balanceo
##separamos ceros y unos
mayorcero<-subset(trainfin,trainfin$resultado==0)
# library(caret)
trainwin<-dummyVars("~.",data=train)
trainfin<-as.data.frame(predict(trainwin,newdata=train))
testwin<-dummyVars("~.",data=test)
testfin<-as.data.frame(predict(testwin,newdata=test))
#Comprobar si la base de datos esta balanceada
balance<-table(train$resultado)
prop.table(balance)
#_________________________________________________________________________________________________________________________
#Balanceo
##separamos ceros y unos
mayorcero<-subset(trainfin,trainfin$resultado==0)
menoruno<-subset(trainfin,trainfin$resultado==1)
#en ambas bases el 20% es prueba
set.seed(1234)
#20% de ceros
sample <- sample.int(nrow(mayorcero), round(.2*nrow(mayorcero)))
mayorcero.test <- mayorcero[sample, ]
mayorcero.rest <- mayorcero[-sample, ]
#20% de unos
sample <- sample.int(nrow(menoruno), round(.2*nrow(menoruno)))
menoruno.test <- menoruno[sample, ]
menoruno.rest <- menoruno[-sample, ]
#fundo las dos
celular.test<-rbind(mayorcero.test,menoruno.test)
nrow(celular.test)
sample <- sample.int(nrow(menoruno.rest), round(.5*nrow(menoruno.rest)))
menoruno.train <- menoruno.rest[sample, ]
menoruno.valid <- menoruno.rest[-sample, ]
#pongo la misma cantidad de ceros y unos en entrenamiento:
sample <- sample.int(nrow(mayorcero.rest), nrow(menoruno.train))
mayorcero.train <- mayorcero.rest[sample, ]
mayorcero.valid <- mayorcero.rest[-sample, ]
#creo entrenamiento y validaci?n
celular.train<-rbind(mayorcero.train,menoruno.train)
celular.valid<-rbind(mayorcero.valid,menoruno.valid)
#chequeo que todo va bien
table(celular.train$resultado)
table(celular.valid$resultado)
table(celular.test$resultado)
prop.table(table(celular.train$resultado))
prop.table(table(celular.valid$resultado))
prop.table(table(celular.test$resultado))
prop.table(table(trainfin$resultado))
X_train <- celular.train %>% select(-c(resultado)) %>% as.matrix()
y_train <- celular.train %>% select(resultado) %>% as.matrix()
#Modelo Random Forest con muestra balanceada
colnames(celular.train) <- unlist(lapply(colnames(celular.train),make.names)) #Random forest solo acpeta variables con nombres sintacticamente correctos
colnames(celular.test) <- unlist(lapply(colnames(celular.test),make.names))
colnames(celular.valid) <- unlist(lapply(colnames(celular.valid),make.names))
colnames(testfin) <- unlist(lapply(colnames(testfin),make.names))
rf <- randomForest(formula = resultado ~ ., data = celular.train,ntree = 1000)
plot(rf)
##Rendimiento en train
predrf <- predict(rf,celular.train)
predrf <- ifelse(predrf > 0.5,1,0) %>% as.numeric()
predrf
pr.train <- prediction(predrf,celular.train$resultado)
curvaROC.train <- performance(pr.train,measure="tpr",x.measure="fpr")
plot(curvaROC.train)
curvaROC.train
auc <- performance(pr.train,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
predrf.test <- predict(rf,celular.test)
predrf.test <- ifelse(predrf.test > 0.5,1,0) %>% as.numeric()
pr.test <- prediction(predrf.test,celular.test$resultado)
curvaROC.test <- performance(pr.test,measure="tpr",x.measure="fpr")
plot(curvaROC.test)
curvaROC.test
auc <- performance(pr.test,measure = "auc")
aucf <- auc@y.values[[1]] #sospecho sobreajusre
aucf
celular.test
aucf
resultado.Final <- predict(rf,testfin)
resultado.Final <- ifelse(resultado.Final >0.5,1,0) %>% as.numeric()
df_finalrf <- cbind(testfin$id,resultado.Final) %>% as.data.frame()
colnames(df_finalrf) <- c("id", "resultado")
df_finalrf$resultado<-as.factor(df_finalrf$resultado)
write.csv(df_finalrf, file="Resultadosrf1S.csv",row.names = F)
test[,escalar] <- apply(train[,escalar],2,scale)
test[,escalar] <- apply(test[,escalar],2,scale)
testwin<-dummyVars("~.",data=test)
testfin<-as.data.frame(predict(testwin,newdata=test))
resultado.Final <- predict(rf,testfin)
colnames(testfin) <- unlist(lapply(colnames(testfin),make.names))
resultado.Final <- predict(rf,testfin)
resultado.Final <- ifelse(resultado.Final >0.5,1,0) %>% as.numeric()
df_finalrf <- cbind(testfin$id,resultado.Final) %>% as.data.frame()
colnames(df_finalrf) <- c("id", "resultado")
df_finalrf$resultado<-as.factor(df_finalrf$resultado)
write.csv(df_finalrf, file="Resultadosrf1S.csv",row.names = F)
if (!require('readxl')) install.packages('readxl')
if (!require('caret')) install.packages('caret')
if (!require('ROCR')) install.packages('ROCR')
if (!require('lift')) install.packages('lift')
if (!require('ggplot2')) install.packages('ggplot2')
library(tidyverse)
library(glmnet)
library(randomForest)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
test<-read_excel("testelco.xlsx")
str(test)
train<-read_excel("traintelco.xlsx")
View(train)
shiny::runApp()
